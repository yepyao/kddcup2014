# the global bias, should be average CTR..
#base_score = 0.0

#num_round = 60
#use_res_buf=1

# ----DO NOT CHANGE these params----------
rt_loss_type = 1
rt_type = 0
#-------------------------
# 3: logistic loss, use taylor expansion as hessian; 7 logistic loss, use 1/4 as hession
# NOTE: output value should be scaled by sigmoid function, 3 and 7 output score before sigmoid transformation
# input should be 0-1
active_type = 3

# parameters for GBRT
# learning rate for GBRT
learning_rate = 0.00001
# minimum weight sum(second order grad ) needed to split a child
min_child_weight = 10.0
# minimum weight sum(second order grad) allowed to be be splitted
min_split_weight = 10.0
# minimum loss change required for a split, gamma|C| in loss, 
min_split_loss = 1.0

# subsample pararemter, use 0.5 part of data to train each tree, have similar effect as Bagging
rt_subsample = 0.5

# regularization method, 2: L2 norm, 1: L1 norm, 0: no extra norm, 3: elastic net
# 0: function complexity = min_split_loss * # nodes, this is original GBRT
# 1: function complexity = min_split_loss * # nodes + reg_lambda | w |
# 2: function complexity = min_split_loss * # nodes + 0.5 * reg_lambda | w |^2
# 3: function complexity = min_split_loss * # nodes + 0.5 * reg_lambda | w | + 0.25 * reg_lambda | w |^2
reg_method = 2
# regularization parameter
reg_lambda = 1

# switch between layerwise weight and normal mode
# 0: normal mode
# 1: layerwise mode, note  we should use regularization to get hierachical reg effect
use_layerwise = 0

# maximum depth allowed
max_depth = 6

# take all params into user features
num_spec_sparse = 20000
num_user = 20000

# baseline method 0, 1 
# 0: no baseline to boost from
# 1: use global feature 0's feature value as base to boost from 
rt_baseline = 0

# num_item indicate number of root we have,  used in additive forest, no need to change if we use single tree
num_item  = 0

# put all dense feature into global feature, set it to number of features we have 
num_global = 0

# used for recom, user specific feature, no need to change 
num_ufeedback = 0

# Use user grouped format, see svdfeature.apexlab.org
model_type = 1
# use GBRT
extend_type = 30

lambda_ap_alpha = 1.0
lambda_ap_start = 1
rank_sample_num = 20

# data for evaluation, binary format, used by svd_feature_infer
test:input_type = 0
test:buffer_feature = "../../model/test.py.all.buffer"
# buffer for training, binary format, created by make_feature_buffer
input_type = 0
buffer_feature = "../../model/train.py.all.buffer"

# folder to store the model file
model_out_folder="./"
